{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify which python environment we are running the notebook on\n",
    "# !pyenv version\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install nltk\n",
    "#%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data from the right data file into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data from csv unzipped files into two dataframes\n",
    "#wine1_df=pd.read_csv(\"~/code/sabrinaauger/wino/raw_data/winemag-data-130k-v2.csv\")\n",
    "wine1_df=pd.read_csv(\"~/code/sabrinaauger/wino/data/raw_data/winemag-data-130k-v2.csv\")\n",
    "#wine2_df=pd.read_csv(\"~/code/sabrinaauger/wino/raw_data/winemag-data_first150k.csv\")\n",
    "wine2_df=pd.read_csv(\"~/code/sabrinaauger/wino/data/raw_data/winemag-data_first150k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "\n",
       "    designation  points  price           province region_1 region_2  \\\n",
       "0  Vulkà Bianco      87    NaN  Sicily & Sardinia     Etna      NaN   \n",
       "1      Avidagos      87   15.0              Douro      NaN      NaN   \n",
       "\n",
       "     taster_name taster_twitter_handle  \\\n",
       "0  Kerin O’Keefe          @kerinokeefe   \n",
       "1     Roger Voss            @vossroger   \n",
       "\n",
       "                                           title         variety  \\\n",
       "0              Nicosia 2013 Vulkà Bianco  (Etna)     White Blend   \n",
       "1  Quinta dos Avidagos 2011 Avidagos Red (Douro)  Portuguese Red   \n",
       "\n",
       "                winery  \n",
       "0              Nicosia  \n",
       "1  Quinta dos Avidagos  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = wine1_df\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and Vectorizing the descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_tokenized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(word_tokenize)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# Importing\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['description_tokenized'] = df['description'].apply(word_tokenize)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec from https://code.google.com/archive/p/word2vec/\n",
    "model = Word2Vec(sentences=df['description_tokenized'], vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def get_sentence_vector(sentence, model):\n",
    "    words_in_vocab = [word for word in sentence if word in model.wv.key_to_index]\n",
    "\n",
    "    # If no words are in the vocabulary, then it becomes 0\n",
    "    if not words_in_vocab:\n",
    "        return [0] * model.vector_size\n",
    "\n",
    "    # Calculate the mean vector for the whole sentence\n",
    "    vector = sum(model.wv[word] for word in words_in_vocab) / len(words_in_vocab)\n",
    "    return vector\n",
    "\n",
    "description_vectorized_df = pd.DataFrame()\n",
    "description_vectorized_df['description'] = df['description_tokenized'].apply(lambda x: get_sentence_vector(x, model))\n",
    "\n",
    "description_vectorized_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wine1_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the others features to then vectorize them depending on their type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting which feature is what\n",
    "y = ['designation']\n",
    "numerical_features_list = ['points', 'price']\n",
    "categorical_features_list = ['country', 'province', 'region_1', 'region_2', 'variety', 'winery']\n",
    "text_features_list = ['taster_name', 'taster_twitter_handle', 'title']\n",
    "# country\tdescription\tdesignation\tpoints\tprice\tprovince\tregion_1\tregion_2\ttaster_name\ttaster_twitter_handle\ttitle\tvariety\twinery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing numeric features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numeric_scaled = scaler.fit_transform(df[numerical_features_list])\n",
    "\n",
    "#wine1_df_scaled = pd.concat([wine1_df, pd.DataFrame(numeric_scaled, columns=['points_scaled', 'price_scaled'])], axis=1)\n",
    "#wine1_df_scaled.head(2)\n",
    "\n",
    "numerical_features_vectorized_df = pd.DataFrame(numeric_scaled, columns=['points', 'price'])\n",
    "numerical_features_vectorized_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "category_encoded = encoder.fit_transform(df[categorical_features_list]).toarray()\n",
    "\n",
    "# wine1_df_scaled = pd.concat([wine1_df, pd.DataFrame(category_encoded, columns=encoder.get_feature_names_out(categorical_features_list))], axis=1)\n",
    "# wine1_df_scaled.head(2)\n",
    "\n",
    "categorical_features_vectorized_df = pd.DataFrame(category_encoded, columns=encoder.get_feature_names_out(categorical_features_list))\n",
    "categorical_features_vectorized_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text_features_vectorized_df = pd.DataFrame()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Vectorize each text feature and concatenate the results\n",
    "for feature in text_features_list:\n",
    "    # Handle NaN values by replacing them with an empty string\n",
    "    df[feature].fillna('', inplace=True)\n",
    "    # Fit and transform the current text feature\n",
    "    feature_vectorized = vectorizer.fit_transform(df[feature])\n",
    "    # Create a DataFrame with the vectorized text feature and concatenate it to the original DataFrame\n",
    "    text_features_vectorized_df = pd.concat([text_features_vectorized_df, pd.DataFrame(feature_vectorized.toarray(), columns=vectorizer.get_feature_names_out([feature]))], axis=1)\n",
    "\n",
    "text_features_vectorized_df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging everything in a new fully vectorized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
